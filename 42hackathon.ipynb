{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "CLIENT_ID = 'u-s4t2ud-cb23abb2c782177b3fdc9c9f0317dafa3e63601a6c0afdcc71693f661a4c5893'\n",
    "CLIENT_SECRET = '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'\n",
    "\n",
    "token_url = \"https://api.intra.42.fr/oauth/token\"\n",
    "token_data = {\n",
    "    'grant_type': 'client_credentials',\n",
    "    'client_id': CLIENT_ID,\n",
    "    'client_secret': CLIENT_SECRET\n",
    "}\n",
    "response = requests.post(token_url, data=token_data)\n",
    "access_token = response.json()['access_token']\n",
    "\n",
    "headers = {'Authorization': f'Bearer {access_token}'}\n",
    "all_users = []\n",
    "page = 1\n",
    "while True:\n",
    "    users_url = f\"https://api.intra.42.fr/v2/campus/35/users?page={page}&per_page=100\"\n",
    "    response = requests.get(users_url, headers=headers)\n",
    "    data = response.json()\n",
    "    if not data:\n",
    "        break\n",
    "    all_users.extend(data)\n",
    "    print(f\"Fetched page {page} with {len(data)} users\")\n",
    "    page += 1\n",
    "\n",
    "os.makedirs('42_profiles', exist_ok=True)\n",
    "\n",
    "for user in all_users:\n",
    "    login = user['login']\n",
    "    image_url = user['image']['link'] if user['image'] and 'link' in user['image'] else None\n",
    "    if not image_url:\n",
    "        print(f\"No image URL for {login}, skipping\")\n",
    "        continue\n",
    "    try:\n",
    "        img_data = requests.get(image_url, timeout=10).content\n",
    "        img = Image.open(BytesIO(img_data))\n",
    "        img.save(f\"42_profiles/{login}.jpg\")\n",
    "        print(f\"Downloaded: {login}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download/save image for {login}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "source_folder = \"42_profiles\"\n",
    "target_folder = \"data\"\n",
    "os.makedirs(target_folder, exist_ok=True)\n",
    "for file in os.listdir(source_folder):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        student_name = file.split('.')[0]\n",
    "        student_folder = os.path.join(target_folder, student_name)\n",
    "        os.makedirs(student_folder, exist_ok=True)\n",
    "        shutil.copy(os.path.join(source_folder, file), os.path.join(student_folder, file))\n",
    "print(\"Dataset folder structure created :white_check_mark:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "source_folder = 'data'\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "for class_folder in os.listdir(source_folder):\n",
    "    class_folder_path = os.path.join(source_folder, class_folder)\n",
    "    if not os.path.isdir(class_folder_path):\n",
    "        continue\n",
    "\n",
    "    for filename in os.listdir(class_folder_path):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            try:\n",
    "                img_path = os.path.join(class_folder_path, filename)\n",
    "                img = cv2.imread(img_path)\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "                if len(faces) == 0:\n",
    "                    print(f\":x: No face found in {filename} inside {class_folder}\")\n",
    "                    continue\n",
    "\n",
    "                x, y, w, h = faces[0]\n",
    "                face = img[y:y+h, x:x+w]\n",
    "\n",
    "                face_image = Image.fromarray(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "                new_filename = filename.rsplit('.', 1)[0] + '_cropped.' + filename.rsplit('.', 1)[1]\n",
    "                save_path = os.path.join(class_folder_path, new_filename)\n",
    "\n",
    "                face_image.save(save_path)\n",
    "                print(f\":white_check_mark: Cropped and saved: {new_filename} in {class_folder}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\":warning: Error processing {filename} in {class_folder}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "source_folder = 'data'\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "for class_folder in os.listdir(source_folder):\n",
    "    class_folder_path = os.path.join(source_folder, class_folder)\n",
    "    if not os.path.isdir(class_folder_path):\n",
    "        continue \n",
    "\n",
    "    for filename in os.listdir(class_folder_path):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            try:\n",
    "                img_path = os.path.join(class_folder_path, filename)\n",
    "                img = cv2.imread(img_path)\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "                if len(faces) == 0:\n",
    "                    print(f\":x: No face found in {filename} inside {class_folder}\")\n",
    "                    continue\n",
    "                x, y, w, h = faces[0]\n",
    "                face = img[y:y+h, x:x+w]\n",
    "                face_image = Image.fromarray(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
    "                new_filename = filename.rsplit('.', 1)[0] + '_cropped.' + filename.rsplit('.', 1)[1]\n",
    "                save_path = os.path.join(class_folder_path, new_filename)\n",
    "                face_image.save(save_path)\n",
    "                print(f\":white_check_mark: Cropped and saved: {new_filename} in {class_folder}\")\n",
    "                pil_img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "                flipped_img = pil_img.transpose(method=Image.FLIP_LEFT_RIGHT)\n",
    "                flipped_filename = filename.rsplit('.', 1)[0] + '_flip.' + filename.rsplit('.', 1)[1]\n",
    "                flipped_img.save(os.path.join(class_folder_path, flipped_filename))\n",
    "                print(f\":white_check_mark: Flipped image saved: {flipped_filename} in {class_folder}\")\n",
    "                rotated_img = pil_img.rotate(-90, expand=True)\n",
    "                rotated_filename = filename.rsplit('.', 1)[0] + '_rot.' + filename.rsplit('.', 1)[1]\n",
    "                rotated_img.save(os.path.join(class_folder_path, rotated_filename))\n",
    "                print(f\":white_check_mark: Rotated image saved: {rotated_filename} in {class_folder}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\":warning: Error processing {filename} in {class_folder}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path('data')\n",
    "files = list(path.glob(\"*.jpg\"))\n",
    "df = pd.DataFrame({\n",
    "    'fname': [f.name for f in files],\n",
    "    'label': [f.stem for f in files]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "images_dir = Path('42_profiles')\n",
    "\n",
    "for img_path in images_dir.iterdir():\n",
    "    if img_path.is_file():\n",
    "        subdir = images_dir / img_path.stem\n",
    "        subdir.mkdir(exist_ok=True)\n",
    "        target_path = subdir / img_path.name\n",
    "        shutil.move(str(img_path), str(target_path))\n",
    "\n",
    "print(\"Done! Each image has been moved into its own folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install --quiet fastai\n",
    "!pip install --quiet --upgrade pip\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "data_path = Path('data')\n",
    "\n",
    "all_files = get_image_files(data_path)\n",
    "\n",
    "class_counts = defaultdict(list)\n",
    "for f in all_files:\n",
    "    class_counts[f.parent.name].append(f)\n",
    "filtered_files = [f for cls, files in class_counts.items() if len(files) > 1 for f in files]\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=lambda _: filtered_files,\n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=lambda f: f.parent.name,\n",
    "     item_tfms=Resize(300)\n",
    ")\n",
    "\n",
    "dls = dblock.dataloaders(data_path, bs=32)\n",
    "\n",
    "dls.show_batch(max_n=9, figsize=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from fastai.vision.utils import verify_image\n",
    "from fastai.vision.all import *\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path('data')\n",
    "all_files = get_image_files(data_path)\n",
    "\n",
    "for f in all_files:\n",
    "    try:\n",
    "        verify_image(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Removing {f} due to error: {e}\")\n",
    "        f.unlink()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=12, figsize=(10, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet34, metrics=accuracy)\n",
    "learn.fine_tune(12)\n",
    "learn.export('/kaggle/working/model_last.pkl')\n",
    "print(\"âœ… Model exported to /kaggle/working/model_last.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install facenet-pytorch\n",
    "\n",
    "from facenet_pytorch import MTCNN\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "mtcnn = MTCNN(keep_all=True, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def crop_face(image_path, save_path=None):\n",
    "    img = Image.open(image_path)\n",
    "    boxes, _ = mtcnn.detect(img)\n",
    "    if boxes is None or len(boxes) == 0:\n",
    "        print(f\"No face found in {image_path}\")\n",
    "        return None\n",
    "    box = boxes[0]\n",
    "    left, top, right, bottom = [int(x) for x in box]\n",
    "    face_img = img.crop((left, top, right, bottom))\n",
    "    if save_path:\n",
    "        face_img.save(save_path)\n",
    "    return face_img\n",
    "cropped_face = crop_face('/kaggle/input/4654645/IMG_6628.jpg')\n",
    "\n",
    "if cropped_face:\n",
    "    pred_class, pred_idx, probs = learn.predict(cropped_face)\n",
    "    print(f\"Predicted student: {pred_class}, Probability: {probs[pred_idx]:.2f}\")\n",
    "else:\n",
    "    print(\"No face detected; cannot predict.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7445632,
     "sourceId": 11849698,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7446888,
     "sourceId": 11851395,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7446943,
     "sourceId": 11851475,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7446971,
     "sourceId": 11851518,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7447039,
     "sourceId": 11851614,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31042,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
